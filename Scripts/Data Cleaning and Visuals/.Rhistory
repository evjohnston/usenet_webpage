# Add a totals row
dataset2_totals <- dataset2_stats %>%
summarize(
NG_ID = "Total",
Threads = sum(Threads),
Comments = sum(Comments),
Authors = n_distinct(all_comments$Author),
Avg_Comments_Per_Thread = sum(Comments) / sum(Threads),
Avg_Sentiment_Score = mean(all_comments$SentimentScore, na.rm = TRUE)
)
dataset2_stats <- bind_rows(dataset2_stats, dataset2_totals)
# Save as HTML or CSV
tab_df(dataset2_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset2_statistics.html"))
library(dplyr)
library(sjPlot)
# Compute statistics grouped by newsgroup
descriptive_stats <- all_comments_in_influential_threads %>%
group_by(newsgroup) %>%
summarise(
Threads = n_distinct(NG_TH_ID),  # Total threads
Total_Comments = n(),  # Total comments
Influential_Authors_Comments = sum(Author %in% influential_author_comments$Author),  # Influential authors' comments
Total_Authors = n_distinct(Author),  # Total unique authors
Influential_Authors = n_distinct(Author[Author %in% influential_author_comments$Author]),  # Unique influential authors
Average_Comments_Per_Thread = n() / n_distinct(NG_TH_ID),  # Avg comments per thread
Avg_Total_Comments_Sentiment_Score = mean(SentimentScore, na.rm = TRUE),  # Avg sentiment for all comments
Avg_Influential_Comments_Sentiment_Score = mean(SentimentScore[Author %in% influential_author_comments$Author], na.rm = TRUE)  # Avg sentiment for influential comments
)
# Add a totals row
totals_row <- descriptive_stats %>%
summarise(
newsgroup = "Total",
Threads = sum(Threads),
Total_Comments = sum(Total_Comments),
Influential_Authors_Comments = sum(Influential_Authors_Comments),
Total_Authors = n_distinct(all_comments_in_influential_threads$Author),
Influential_Authors = n_distinct(influential_author_comments$Author),
Average_Comments_Per_Thread = sum(Total_Comments) / sum(Threads),
Avg_Total_Comments_Sentiment_Score = mean(all_comments_in_influential_threads$SentimentScore, na.rm = TRUE),
Avg_Influential_Comments_Sentiment_Score = mean(influential_author_comments$SentimentScore, na.rm = TRUE)
)
# Combine newsgroup stats with totals row
descriptive_stats <- bind_rows(descriptive_stats, totals_row)
# Save and display the table
tab_df(descriptive_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset3_statistics.html"))
# Filter influential authors' participation in Dataset 3
dataset3_influential_comments <- relevant_comments %>%
filter(Author %in% influential_authors$Author)
dataset3_influential_threads <- relevant_threads %>%
filter(NG_TH_ID %in% dataset3_influential_comments$NG_TH_ID)
# Add descriptive statistics for each influential author
author_stats <- dataset3_influential_comments %>%
group_by(Author) %>%
summarise(
Influence = unique(influential_authors$InfluenceScore[influential_authors$Author == Author]),
Num_Comments = n_distinct(TH_CM_ID),  # Number of comments authored
Num_Threads = n_distinct(NG_TH_ID),  # Number of threads participated in
Threads_Started = sum(CM_ID == "CM00001", na.rm = TRUE),  # Threads started
Avg_Sentiment = mean(SentimentScore, na.rm = TRUE),  # Average sentiment score
)
# Filter out authors with missing Influence scores and sort by Influence
author_stats <- author_stats %>%
filter(!is.na(Influence)) %>%
arrange(desc(Influence))
# Save the table as an HTML file
tab_df(author_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset3_author_statistics.html"))
# Filter influential authors' participation in Dataset 3
dataset3_influential_comments <- relevant_comments %>%
filter(Author %in% influential_authors$Author)
dataset3_influential_threads <- relevant_threads %>%
filter(NG_TH_ID %in% dataset3_influential_comments$NG_TH_ID)
# Add descriptive statistics for each influential author
author_stats <- dataset3_influential_comments %>%
group_by(Author) %>%
summarise(
Influence = first(influential_authors$InfluenceScore[influential_authors$Author == Author]),
Num_Comments = n_distinct(TH_CM_ID),
Num_Threads = n_distinct(NG_TH_ID),
Threads_Started = sum(CM_ID == "CM00001", na.rm = TRUE),
Avg_Sentiment = mean(SentimentScore, na.rm = TRUE)
)
# Filter authors with missing Influence scores and sort by Influence
author_stats <- author_stats %>%
filter(!is.na(Influence)) %>%
arrange(desc(Influence))
# Save the table as an HTML file
tab_df(author_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset3_author_statistics.html"))
dplyr::last_dplyr_warnings()
library(sjPlot)
# Dataset 1: All Comments
dataset1_summary <- all_comments %>%
group_by(newsgroup) %>%
summarize(
Threads = n_distinct(TH_ID),
Comments = n(),
Authors = n_distinct(Author),
Avg_Comments_Per_Thread = Comments / Threads,
Avg_Sentiment_Score = mean(SentimentScore, na.rm = TRUE)
)
# Add a totals row
dataset1_totals <- dataset1_summary %>%
summarize(
newsgroup = "Total",
Threads = sum(Threads),
Comments = sum(Comments),
Authors = n_distinct(all_comments$Author),
Avg_Comments_Per_Thread = sum(Comments) / sum(Threads),
Avg_Sentiment_Score = mean(all_comments$SentimentScore, na.rm = TRUE)
)
# Combine the summary with the totals row
dataset1_summary <- bind_rows(dataset1_summary, dataset1_totals)
# Save or print the summary
tab_df(dataset1_summary, file = file.path(output_directory, "Images and Tables/Tables/dataset1_statistics.html"))
dataset2_stats <- relevant_comments %>%
group_by(newsgroup) %>%
summarize(
Threads = n_distinct(TH_ID),
Comments = n(),
Authors = n_distinct(Author),
Avg_Comments_Per_Thread = Comments / Threads,
Avg_Sentiment_Score = mean(SentimentScore, na.rm = TRUE)
)
# Add a totals row
dataset2_totals <- dataset2_stats %>%
summarize(
newsgroup = "Total",
Threads = sum(Threads),
Comments = sum(Comments),
Authors = n_distinct(all_comments$Author),
Avg_Comments_Per_Thread = sum(Comments) / sum(Threads),
Avg_Sentiment_Score = mean(all_comments$SentimentScore, na.rm = TRUE)
)
dataset2_stats <- bind_rows(dataset2_stats, dataset2_totals)
# Save as HTML or CSV
tab_df(dataset2_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset2_statistics.html"))
# Step 1: Deduplicate influential_authors by Author
influential_authors <- influential_authors %>%
group_by(Author) %>%
summarise(InfluenceScore = first(InfluenceScore))  # Choose the first InfluenceScore (or use mean/max if needed)
# Step 2: Add descriptive statistics for each influential author
author_stats <- dataset3_influential_comments %>%
group_by(Author) %>%
summarise(
Influence = first(influential_authors$InfluenceScore[influential_authors$Author == Author]),
Num_Comments = n_distinct(TH_CM_ID),  # Number of comments authored
Num_Threads = n_distinct(NG_TH_ID),   # Number of threads participated in
Threads_Started = sum(CM_ID == "CM00001", na.rm = TRUE),  # Threads started
Avg_Sentiment = mean(SentimentScore, na.rm = TRUE)  # Average sentiment score
)
# Step 3: Filter authors with missing Influence scores and sort by Influence
author_stats <- author_stats %>%
filter(!is.na(Influence)) %>%
arrange(desc(Influence))
# Step 4: Save the table as an HTML file
tab_df(author_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset3_author_statistics.html"))
# Filter influential authors' participation in Dataset 3
dataset3_influential_comments <- relevant_comments %>%
filter(Author %in% influential_authors$Author)
dataset3_influential_threads <- relevant_threads %>%
filter(NG_TH_ID %in% dataset3_influential_comments$NG_TH_ID)
# Add descriptive statistics for each influential author
author_stats <- dataset3_influential_comments %>%
group_by(Author) %>%
summarise(
Influence = first(influential_authors$InfluenceScore[influential_authors$Author == Author]),
Num_Comments = n_distinct(TH_CM_ID),
Num_Threads = n_distinct(NG_TH_ID),
Threads_Started = sum(CM_ID == "CM00001", na.rm = TRUE),
Avg_Sentiment = mean(SentimentScore, na.rm = TRUE)
)
# Filter authors with missing Influence scores and sort by Influence
author_stats <- author_stats %>%
filter(!is.na(Influence)) %>%
arrange(desc(Influence))
# Save the table as an HTML file
tab_df(author_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset3_author_statistics.html"))
# Step 1: Join influential_authors to dataset3_influential_comments
dataset3_influential_comments <- dataset3_influential_comments %>%
left_join(influential_authors, by = "Author")  # Join InfluenceScore based on Author
# Step 2: Add descriptive statistics for each influential author
author_stats <- dataset3_influential_comments %>%
group_by(Author) %>%
summarise(
Influence = first(InfluenceScore),  # Influence is now directly available
Num_Comments = n_distinct(TH_CM_ID),  # Number of comments authored
Num_Threads = n_distinct(NG_TH_ID),   # Number of threads participated in
Threads_Started = sum(CM_ID == "CM00001", na.rm = TRUE),  # Threads started
Avg_Sentiment = mean(SentimentScore, na.rm = TRUE)  # Average sentiment score
)
# Step 3: Filter authors with missing Influence scores and sort by Influence
author_stats <- author_stats %>%
filter(!is.na(Influence)) %>%
arrange(desc(Influence))
# Step 4: Save the table as an HTML file
tab_df(author_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset3_author_statistics.html"))
reticulate::repl_python()
library(sjPlot)
# Dataset 1: All Comments
dataset1_summary <- all_comments %>%
group_by(newsgroup) %>%
summarize(
Threads = n_distinct(TH_ID),
Comments = n(),
Authors = n_distinct(Author),
Avg_Comments_Per_Thread = Comments / Threads,
Avg_Sentiment_Score = mean(SentimentScore, na.rm = TRUE)
)
# Add a totals row
dataset1_totals <- dataset1_summary %>%
summarize(
newsgroup = "Total",
Threads = sum(Threads),
Comments = sum(Comments),
Authors = n_distinct(all_comments$Author),
Avg_Comments_Per_Thread = sum(Comments) / sum(Threads),
Avg_Sentiment_Score = mean(all_comments$SentimentScore, na.rm = TRUE)
)
# Combine the summary with the totals row
dataset1_summary <- bind_rows(dataset1_summary, dataset1_totals)
# Save or print the summary
tab_df(dataset1_summary, file = file.path(output_directory, "Images and Tables/Tables/dataset1_statistics.html"))
dataset2_stats <- relevant_comments %>%
group_by(newsgroup) %>%
summarize(
Threads = n_distinct(TH_ID),
Comments = n(),
Authors = n_distinct(Author),
Avg_Comments_Per_Thread = Comments / Threads,
Avg_Sentiment_Score = mean(SentimentScore, na.rm = TRUE)
)
# Add a totals row
dataset2_totals <- dataset2_stats %>%
summarize(
newsgroup = "Total",
Threads = sum(Threads),
Comments = sum(Comments),
Authors = n_distinct(relevant_comments$Author),
Avg_Comments_Per_Thread = sum(Comments) / sum(Threads),
Avg_Sentiment_Score = mean(relevant_comments$SentimentScore, na.rm = TRUE)
)
dataset2_stats <- bind_rows(dataset2_stats, dataset2_totals)
# Save as HTML or CSV
tab_df(dataset2_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset2_statistics.html"))
library(dplyr)
library(sjPlot)
# Compute statistics grouped by newsgroup
descriptive_stats <- all_comments_in_influential_threads %>%
group_by(newsgroup) %>%
summarise(
Threads = n_distinct(NG_TH_ID),  # Total threads
Total_Comments = n(),  # Total comments
Influential_Authors_Comments = sum(Author %in% influential_author_comments$Author),  # Influential authors' comments
Total_Authors = n_distinct(Author),  # Total unique authors
Influential_Authors = n_distinct(Author[Author %in% influential_author_comments$Author]),  # Unique influential authors
Average_Comments_Per_Thread = n() / n_distinct(NG_TH_ID),  # Avg comments per thread
Avg_Total_Comments_Sentiment_Score = mean(SentimentScore, na.rm = TRUE),  # Avg sentiment for all comments
Avg_Influential_Comments_Sentiment_Score = mean(SentimentScore[Author %in% influential_author_comments$Author], na.rm = TRUE)  # Avg sentiment for influential comments
)
# Add a totals row
totals_row <- descriptive_stats %>%
summarise(
newsgroup = "Total",
Threads = sum(Threads),
Total_Comments = sum(Total_Comments),
Influential_Authors_Comments = sum(Influential_Authors_Comments),
Total_Authors = n_distinct(all_comments_in_influential_threads$Author),
Influential_Authors = n_distinct(influential_author_comments$Author),
Average_Comments_Per_Thread = sum(Total_Comments) / sum(Threads),
Avg_Total_Comments_Sentiment_Score = mean(all_comments_in_influential_threads$SentimentScore, na.rm = TRUE),
Avg_Influential_Comments_Sentiment_Score = mean(influential_author_comments$SentimentScore, na.rm = TRUE)
)
# Combine newsgroup stats with totals row
descriptive_stats <- bind_rows(descriptive_stats, totals_row)
# Save and display the table
tab_df(descriptive_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset3_statistics.html"))
# Step 1: Join influential_authors to dataset3_influential_comments
dataset3_influential_comments <- dataset3_influential_comments %>%
left_join(influential_authors, by = "Author")  # Join InfluenceScore based on Author
# Step 2: Add descriptive statistics for each influential author
author_stats <- dataset3_influential_comments %>%
group_by(Author) %>%
summarise(
Influence = first(InfluenceScore),  # Influence is now directly available
Num_Comments = n_distinct(TH_CM_ID),  # Number of comments authored
Num_Threads = n_distinct(NG_TH_ID),   # Number of threads participated in
Threads_Started = sum(CM_ID == "CM00001", na.rm = TRUE),  # Threads started
Avg_Sentiment = mean(SentimentScore, na.rm = TRUE)  # Average sentiment score
)
rm(list = ls())
knitr::opts_knit$set(root.dir = '/Users/emerson/Github/usenet_webpage')
# Load Libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(readr)
library(syuzhet)
# Directories
output_directory <- "/Users/emerson/Github/usenet_webpage"
threads_directory <- file.path(output_directory, "CSV Files/Threads")
comments_directory <- file.path(output_directory, "CSV Files/Comments")
# Load the datasets
all_threads <- read.csv(file.path(threads_directory, "combined_threads.csv"))
all_comments <- read.csv(file.path(comments_directory, "combined_comments_AS.csv"))
# Map newsgroups to IDs
newsgroup_ids <- c("netmed" = "NG01", "netmotss" = "NG02", "netnews" = "NG03",
"netpolitics" = "NG04", "netreligion" = "NG05", "netsingles" = "NG06")
# Threads cleaning
all_threads <- all_threads %>%
mutate(NG_ID = factor(newsgroup, levels = names(newsgroup_ids), labels = newsgroup_ids),
NG_TH_ID = paste(NG_ID, ThreadID, sep = "_")) %>%
rename(TH_ID = ThreadID) %>%
select(NG_TH_ID, TH_ID, NG_ID, everything()) %>%
mutate(Date = as.Date(Date, format = "%m/%d/%y"))
# Comments cleaning
all_comments <- all_comments %>%
rename(
TH_CM_ID = Unique.Comment.ID,
TH_ID = Thread.ID,
CM_ID = Comment.ID) %>%
mutate(NG_ID = factor(newsgroup, levels = names(newsgroup_ids), labels = newsgroup_ids),
NG_TH_CM_ID = paste(NG_ID, TH_CM_ID, sep = "_"),
NG_TH_ID = paste(NG_ID, TH_ID, sep = "_")) %>%
select(NG_TH_CM_ID, NG_TH_ID, TH_CM_ID, CM_ID, TH_ID, NG_ID, everything()) %>%
mutate(Date.and.Time = as.POSIXct(gsub("[^[:alnum:] [:punct:]]", "", Date.and.Time), format = "%b %d, %Y, %I:%M:%S%p"),
Hour = as.numeric(format(Date.and.Time, "%H")),
Date = as.Date(Date.and.Time))
# Add sentiment scores
all_comments <- all_comments %>%
mutate(SentimentScore = get_sentiment(Full.Text, method = "afinn"))
all_comments <- all_comments %>%
mutate(
Author = case_when(
Author == "Cowenton Volunteer Fire Department" ~ "Ron Natalie",
TRUE ~ Author
)
)
write.csv(all_threads, file.path(threads_directory, "dataset1_threads.csv"), row.names = FALSE)
write.csv(all_comments, file.path(comments_directory, "dataset1_comments.csv"), row.names = FALSE)
# Define AIDS-related keywords
aids_keywords <- c("aids", "acquired immune deficiency syndrome", "human immunodeficiency virus",
"gay-related immune deficiency", "gay plague",
"hiv", "htlv", "human t-lymphotropic virus", "gay cancer", "kaposi's sarcoma",
"slim disease", "pneumocystis pneumonia", "gay disease", "homosexual disease")
# Step 1: Filter threads by `Thread.Title` containing AIDS-related keywords
relevant_threads <- all_threads %>%
filter(str_detect(tolower(Thread.Title), paste(tolower(aids_keywords), collapse = "|")))
# Step 2: Get `NG_TH_ID`s for relevant threads
relevant_thread_ids <- relevant_threads$NG_TH_ID
# Step 3: Filter comments associated with these threads
relevant_comments <- all_comments %>%
filter(NG_TH_ID %in% relevant_thread_ids)
write.csv(relevant_threads, file.path(threads_directory, "dataset2_threads.csv"), row.names = FALSE)
write.csv(relevant_comments, file.path(comments_directory, "dataset2_comments.csv"), row.names = FALSE)
# Load required libraries
library(dplyr)
library(igraph)
# Step 2: Create an author co-participation network
author_pairs <- relevant_comments %>%
filter(!is.na(TH_ID)) %>%
group_by(TH_ID) %>%
summarise(
Pairs = list(if (length(unique(Author)) > 1) {
as.data.frame(t(combn(unique(Author), 2)))
} else {
NULL
})
) %>%
unnest(Pairs, keep_empty = TRUE) %>%
rename(Author1 = V1, Author2 = V2) %>%
count(Author1, Author2, name = "Weight") %>%
filter(!is.na(Author1) & !is.na(Author2))
# Step 3: Create a graph from the author pairs
author_network <- graph_from_data_frame(author_pairs, directed = FALSE)
# Step 4: Identify influential authors using degree centrality
degree_centrality <- strength(author_network, mode = "all", weights = E(author_network)$Weight)
# Create a data frame of authors and their influence scores
influential_authors <- data.frame(
Author = names(degree_centrality),
InfluenceScore = degree_centrality
) %>%
arrange(desc(InfluenceScore)) %>%
head(20) # Select the top 20 influential authors
# Save the list of influential authors
write.csv(influential_authors, file.path(output_directory, "CSV Files", "influential_authors.csv"), row.names = FALSE)
# Print the top influential authors
print(influential_authors)
# Step 5: Filter comments authored by influential authors
influential_author_comments <- relevant_comments %>%
filter(Author %in% influential_authors$Author)
# Step 6: Identify threads with at least one influential author
influential_threads <- relevant_threads %>%
filter(NG_TH_ID %in% influential_author_comments$NG_TH_ID)
# Step 7: Include all comments in threads with influential authors
all_comments_in_influential_threads <- relevant_comments %>%
filter(NG_TH_ID %in% influential_threads$NG_TH_ID)
# Step 8: Save the final datasets
write.csv(influential_threads,
file.path(threads_directory, "dataset3_threads.csv"),
row.names = FALSE)
write.csv(all_comments_in_influential_threads,
file.path(comments_directory, "dataset3_comments_all.csv"),
row.names = FALSE)
write.csv(influential_author_comments,
file.path(comments_directory, "dataset3_comments_onlyinfluential.csv"),
row.names = FALSE)
# Step 9: Print summary statistics
cat("Number of threads involving influential authors:", nrow(influential_threads), "\n")
cat("Number of comments in these threads (all comments):", nrow(all_comments_in_influential_threads), "\n")
cat("Number of comments by influential authors only:", nrow(influential_author_comments), "\n")
library(sjPlot)
# Dataset 1: All Comments
dataset1_summary <- all_comments %>%
group_by(newsgroup) %>%
summarize(
Threads = n_distinct(TH_ID),
Comments = n(),
Authors = n_distinct(Author),
Avg_Comments_Per_Thread = Comments / Threads,
Avg_Sentiment_Score = mean(SentimentScore, na.rm = TRUE)
)
# Add a totals row
dataset1_totals <- dataset1_summary %>%
summarize(
newsgroup = "Total",
Threads = sum(Threads),
Comments = sum(Comments),
Authors = n_distinct(all_comments$Author),
Avg_Comments_Per_Thread = sum(Comments) / sum(Threads),
Avg_Sentiment_Score = mean(all_comments$SentimentScore, na.rm = TRUE)
)
# Combine the summary with the totals row
dataset1_summary <- bind_rows(dataset1_summary, dataset1_totals)
# Save or print the summary
tab_df(dataset1_summary, file = file.path(output_directory, "Images and Tables/Tables/dataset1_statistics.html"))
dataset2_stats <- relevant_comments %>%
group_by(newsgroup) %>%
summarize(
Threads = n_distinct(TH_ID),
Comments = n(),
Authors = n_distinct(Author),
Avg_Comments_Per_Thread = Comments / Threads,
Avg_Sentiment_Score = mean(SentimentScore, na.rm = TRUE)
)
# Add a totals row
dataset2_totals <- dataset2_stats %>%
summarize(
newsgroup = "Total",
Threads = sum(Threads),
Comments = sum(Comments),
Authors = n_distinct(relevant_comments$Author),
Avg_Comments_Per_Thread = sum(Comments) / sum(Threads),
Avg_Sentiment_Score = mean(relevant_comments$SentimentScore, na.rm = TRUE)
)
dataset2_stats <- bind_rows(dataset2_stats, dataset2_totals)
# Save as HTML or CSV
tab_df(dataset2_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset2_statistics.html"))
library(dplyr)
library(sjPlot)
# Compute statistics grouped by newsgroup
descriptive_stats <- all_comments_in_influential_threads %>%
group_by(newsgroup) %>%
summarise(
Threads = n_distinct(NG_TH_ID),  # Total threads
Total_Comments = n(),  # Total comments
Influential_Authors_Comments = sum(Author %in% influential_author_comments$Author),  # Influential authors' comments
Total_Authors = n_distinct(Author),  # Total unique authors
Influential_Authors = n_distinct(Author[Author %in% influential_author_comments$Author]),  # Unique influential authors
Average_Comments_Per_Thread = n() / n_distinct(NG_TH_ID),  # Avg comments per thread
Avg_Total_Comments_Sentiment_Score = mean(SentimentScore, na.rm = TRUE),  # Avg sentiment for all comments
Avg_Influential_Comments_Sentiment_Score = mean(SentimentScore[Author %in% influential_author_comments$Author], na.rm = TRUE)  # Avg sentiment for influential comments
)
# Add a totals row
totals_row <- descriptive_stats %>%
summarise(
newsgroup = "Total",
Threads = sum(Threads),
Total_Comments = sum(Total_Comments),
Influential_Authors_Comments = sum(Influential_Authors_Comments),
Total_Authors = n_distinct(all_comments_in_influential_threads$Author),
Influential_Authors = n_distinct(influential_author_comments$Author),
Average_Comments_Per_Thread = sum(Total_Comments) / sum(Threads),
Avg_Total_Comments_Sentiment_Score = mean(all_comments_in_influential_threads$SentimentScore, na.rm = TRUE),
Avg_Influential_Comments_Sentiment_Score = mean(influential_author_comments$SentimentScore, na.rm = TRUE)
)
# Combine newsgroup stats with totals row
descriptive_stats <- bind_rows(descriptive_stats, totals_row)
# Save and display the table
tab_df(descriptive_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset3_statistics.html"))
# Step 1: Join influential_authors to dataset3_influential_comments
dataset3_influential_comments <- dataset3_influential_comments %>%
left_join(influential_authors, by = "Author")  # Join InfluenceScore based on Author
# Step 1: Join influential_authors to dataset3_influential_comments
dataset3_influential_comments <- influential_author_comments %>%
left_join(influential_authors, by = "Author")  # Join InfluenceScore based on Author
# Step 2: Add descriptive statistics for each influential author
author_stats <- dataset3_influential_comments %>%
group_by(Author) %>%
summarise(
Influence = first(InfluenceScore),  # Influence is now directly available
Num_Comments = n_distinct(TH_CM_ID),  # Number of comments authored
Num_Threads = n_distinct(NG_TH_ID),   # Number of threads participated in
Threads_Started = sum(CM_ID == "CM00001", na.rm = TRUE),  # Threads started
Avg_Sentiment = mean(SentimentScore, na.rm = TRUE)  # Average sentiment score
)
# Step 3: Filter authors with missing Influence scores and sort by Influence
author_stats <- author_stats %>%
filter(!is.na(Influence)) %>%
arrange(desc(Influence))
# Step 4: Save the table as an HTML file
tab_df(author_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset3_author_statistics.html"))
reticulate::repl_python()
reticulate::repl_python()
