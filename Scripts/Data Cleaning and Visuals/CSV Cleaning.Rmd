---
title: "Usenet Project - CSV Cleaning"
author: "Emerson Johnston"
lastmodifeddate: "2024-08-07"
output:
  pdf_document: default
  html_document:
    df_print: paged
---


```{r Old Read and Merge, eval=FALSE, include=FALSE}
netmed_threads <- read.csv(file.path(threads_directory, "netmed_threads.csv"))
netmotss_threads <- read.csv(file.path(threads_directory, "netmotss_threads.csv"))
netnews_threads <- read.csv(file.path(threads_directory, "netnews_threads.csv"))
netpolitics_threads <- read.csv(file.path(threads_directory, "netpolitics_threads.csv"))
netreligion_threads <- read.csv(file.path(threads_directory, "netreligion_threads.csv"))
netsingles_threads <- read.csv(file.path(threads_directory, "netsingles_threads.csv"))

netmed_comments <- read.csv(file.path(comments_directory, "netmed_comments.csv"))
netmotss_comments <- read.csv(file.path(comments_directory, "netmotss_comments.csv"))
netnews_comments <- read.csv(file.path(comments_directory, "netnews_comments.csv"))
netpolitics_comments <- read.csv(file.path(comments_directory, "netpolitics_comments.csv"))
netreligion_comments <- read.csv(file.path(comments_directory, "netreligion_comments.csv"))
netsingles_comments <- read.csv(file.path(comments_directory, "netsingles_comments.csv"))

netmed_threads$newsgroup <- "netmed"
netmotss_threads$newsgroup <- "netmotss"
netnews_threads$newsgroup <- "netnews"
netpolitics_threads$newsgroup <- "netpolitics"
netreligion_threads$newsgroup <- "netreligion"
netsingles_threads$newsgroup <- "netsingles"

all_threads <- rbind(netmed_threads, netmotss_threads, netnews_threads, netpolitics_threads, netreligion_threads, netsingles_threads)

netmed_comments$newsgroup <- "netmed"
netmotss_comments$newsgroup <- "netmotss"
netnews_comments$newsgroup <- "netnews"
netpolitics_comments$newsgroup <- "netpolitics"
netreligion_comments$newsgroup <- "netreligion"
netsingles_comments$newsgroup <- "netsingles"

all_comments <- rbind(netmed_comments, netmotss_comments, netnews_comments, netpolitics_comments, netreligion_comments, netsingles_comments)

threads_directory <- "CSV Files/Threads"
comments_directory <- "CSV Files/Comments"

write.csv(all_threads, file.path(threads_directory, "combined_threads.csv"), row.names = FALSE)
write.csv(all_comments, file.path(comments_directory, "combined_comments.csv"), row.names = FALSE)
```

# Maintainence
```{r Reset and Set Working Directory}
rm(list = ls()) 
knitr::opts_knit$set(root.dir = '/Users/emerson/Github/usenet_webpage')
```

```{r Load Libraries, Directories, and Datasets}
# Load Libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(readr)
library(syuzhet)

# Directories
output_directory <- "/Users/emerson/Github/usenet_webpage"
threads_directory <- file.path(output_directory, "CSV Files/Threads")
comments_directory <- file.path(output_directory, "CSV Files/Comments")

# Load the datasets
all_threads <- read.csv(file.path(threads_directory, "combined_threads.csv"))
all_comments <- read.csv(file.path(comments_directory, "combined_comments.csv"))
```

## Dataset 1 - All Comments Cleaned
```{r Dataset Cleaning}
# Map newsgroups to IDs
newsgroup_ids <- c("netmed" = "NG01", "netmotss" = "NG02", "netnews" = "NG03",
                   "netpolitics" = "NG04", "netreligion" = "NG05", "netsingles" = "NG06")

# Threads cleaning
all_threads <- all_threads %>%
  mutate(NG_ID = factor(newsgroup, levels = names(newsgroup_ids), labels = newsgroup_ids),
         NG_TH_ID = paste(NG_ID, ThreadID, sep = "_")) %>%
  rename(TH_ID = ThreadID) %>%
  select(NG_TH_ID, TH_ID, NG_ID, everything()) %>%
  mutate(Date = as.Date(Date, format = "%m/%d/%y"))

# Comments cleaning
all_comments <- all_comments %>%
    rename(        
        TH_CM_ID = Unique.Comment.ID,
        TH_ID = Thread.ID,
        CM_ID = Comment.ID) %>%
  mutate(NG_ID = factor(newsgroup, levels = names(newsgroup_ids), labels = newsgroup_ids),
         NG_TH_CM_ID = paste(NG_ID, TH_CM_ID, sep = "_"),
         NG_TH_ID = paste(NG_ID, TH_ID, sep = "_")) %>%
  select(NG_TH_CM_ID, NG_TH_ID, TH_CM_ID, CM_ID, TH_ID, NG_ID, everything()) %>%
  mutate(Date.and.Time = as.POSIXct(gsub("[^[:alnum:] [:punct:]]", "", Date.and.Time), format = "%b %d, %Y, %I:%M:%S%p"),
         Hour = as.numeric(format(Date.and.Time, "%H")),
         Date = as.Date(Date.and.Time))
         

# Replace mentions of specific authors
all_comments <- all_comments %>%
  mutate(
    Author = case_when(
      Author == "SEVENER" ~ "Tim Sevener",
      Author == "The Polymath" ~ "Jerry Hollombe",
      Author == "fau...@ucbcad.uucp" ~ "Wayne A. Christopher",
      Author == "bi...@persci.uucp" ~ "Bill Swan",
      Author == "wer...@aecom.uucp" ~ "Craig Werner",
      TRUE ~ Author # Retain other authors as-is
    )
  )

# Add sentiment scores
all_comments <- all_comments %>%
  mutate(SentimentScore = get_sentiment(Full.Text, method = "afinn"))

write.csv(all_threads, file.path(threads_directory, "dataset1_threads.csv"), row.names = FALSE)
write.csv(all_comments, file.path(comments_directory, "dataset1_comments.csv"), row.names = FALSE)
```

## Dataset 2 - AIDS-Related Comments, as Determined by Titles (1982–1986)
```{r Title Based Filtering}
# Define AIDS-related keywords
aids_keywords <- c("aids", "acquired immune deficiency syndrome", "human immunodeficiency virus", 
  "gay-related immune deficiency", "gay plague",
  "hiv", "htlv", "human t-lymphotropic virus", "gay cancer", "kaposi's sarcoma",
  "slim disease", "pneumocystis pneumonia", "gay disease", "homosexual disease")

# Step 1: Filter threads by `Thread.Title` containing AIDS-related keywords
relevant_threads <- all_threads %>%
  filter(str_detect(tolower(Thread.Title), paste(tolower(aids_keywords), collapse = "|")))

# Step 2: Get `NG_TH_ID`s for relevant threads
relevant_thread_ids <- relevant_threads$NG_TH_ID

# Step 3: Filter comments associated with these threads
relevant_comments <- all_comments %>%
  filter(NG_TH_ID %in% relevant_thread_ids)

write.csv(relevant_threads, file.path(threads_directory, "dataset2_threads.csv"), row.names = FALSE)
write.csv(relevant_comments, file.path(comments_directory, "dataset2_comments.csv"), row.names = FALSE)
```

## Dataset 3 - AIDS-Related Comments (1982–1986) - Filtered By Influential Authors Comments 
```{r Identify Influential Authors}
# Load required libraries
library(dplyr)
library(igraph)

# Step 2: Create an author co-participation network
author_pairs <- relevant_comments %>%
  filter(!is.na(TH_ID)) %>%
  group_by(TH_ID) %>%
  summarise(
    Pairs = list(if (length(unique(Author)) > 1) {
      as.data.frame(t(combn(unique(Author), 2)))
    } else {
      NULL
    })
  ) %>%
  unnest(Pairs, keep_empty = TRUE) %>%
  rename(Author1 = V1, Author2 = V2) %>%
  count(Author1, Author2, name = "Weight") %>%
  filter(!is.na(Author1) & !is.na(Author2))

# Step 3: Create a graph from the author pairs
author_network <- graph_from_data_frame(author_pairs, directed = FALSE)

# Step 4: Identify influential authors using degree centrality
degree_centrality <- strength(author_network, mode = "all", weights = E(author_network)$Weight)

# Create a data frame of authors and their influence scores
influential_authors <- data.frame(
  Author = names(degree_centrality),
  InfluenceScore = degree_centrality
) %>%
  arrange(desc(InfluenceScore)) %>%
  head(20) # Select the top 20 influential authors

# Save the list of influential authors
write.csv(influential_authors, file.path(output_directory, "CSV Files", "influential_authors.csv"), row.names = FALSE)

# Print the top influential authors
print(influential_authors)
```

```{r Influential Authors Comments and Threads}
# Step 5: Filter comments authored by influential authors
influential_author_comments <- relevant_comments %>%
  filter(Author %in% influential_authors$Author)

# Step 6: Identify threads with at least one influential author
influential_threads <- relevant_threads %>%
  filter(NG_TH_ID %in% influential_author_comments$NG_TH_ID)

# Step 7: Include all comments in threads with influential authors
all_comments_in_influential_threads <- relevant_comments %>%
  filter(NG_TH_ID %in% influential_threads$NG_TH_ID)

# Step 8: Save the final datasets
write.csv(influential_threads, 
          file.path(threads_directory, "dataset3_threads.csv"), 
          row.names = FALSE)
write.csv(all_comments_in_influential_threads, 
          file.path(comments_directory, "dataset3_comments_all.csv"), 
          row.names = FALSE)
write.csv(influential_author_comments, 
          file.path(comments_directory, "dataset3_comments_onlyinfluential.csv"), 
          row.names = FALSE)

# Step 9: Print summary statistics
cat("Number of threads involving influential authors:", nrow(influential_threads), "\n")
cat("Number of comments in these threads (all comments):", nrow(all_comments_in_influential_threads), "\n")
cat("Number of comments by influential authors only:", nrow(influential_author_comments), "\n")
```

# Descriptive Statistics Tables
## Dataset 1 Descriptive Statistics
```{r Dataset 1 Descriptive Statistics}
library(sjPlot)

# Dataset 1: All Comments
dataset1_summary <- all_comments %>%
  group_by(newsgroup) %>%
  summarize(
    Threads = n_distinct(TH_ID),
    Comments = n(),
    Authors = n_distinct(Author),
    Avg_Comments_Per_Thread = Comments / Threads,
    Avg_Sentiment_Score = mean(SentimentScore, na.rm = TRUE)
  )

# Add a totals row
dataset1_totals <- dataset1_summary %>%
  summarize(
    NG_ID = "Total",
    Threads = sum(Threads),
    Comments = sum(Comments),
    Authors = n_distinct(all_comments$Author),
    Avg_Comments_Per_Thread = sum(Comments) / sum(Threads),
    Avg_Sentiment_Score = mean(all_comments$SentimentScore, na.rm = TRUE)
  )

# Combine the summary with the totals row
dataset1_summary <- bind_rows(dataset1_summary, dataset1_totals)

# Save or print the summary
tab_df(dataset1_summary, file = file.path(output_directory, "Images and Tables/Tables/dataset1_statistics.html"))
```

## Dataset 2 Descriptive Statistics
```{r Dataset 2 Descriptive Statistics}
dataset2_stats <- relevant_comments %>%
  group_by(newsgroup) %>%
  summarize(
    Threads = n_distinct(TH_ID),
    Comments = n(),
    Authors = n_distinct(Author),
    Avg_Comments_Per_Thread = Comments / Threads,
    Avg_Sentiment_Score = mean(SentimentScore, na.rm = TRUE)
  )

# Add a totals row
dataset2_totals <- dataset2_stats %>%
  summarize(
    NG_ID = "Total",
    Threads = sum(Threads),
    Comments = sum(Comments),
    Authors = n_distinct(all_comments$Author),
    Avg_Comments_Per_Thread = sum(Comments) / sum(Threads),
    Avg_Sentiment_Score = mean(all_comments$SentimentScore, na.rm = TRUE)
  )

dataset2_stats <- bind_rows(dataset2_stats, dataset2_totals)

# Save as HTML or CSV
tab_df(dataset2_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset2_statistics.html"))
```

## Dataset 3 Descriptive Statistics
```{r Dataset 4 Descriptive Statistics}
library(dplyr)
library(sjPlot)

# Compute statistics grouped by newsgroup
descriptive_stats <- all_comments_in_influential_threads %>%
  group_by(newsgroup) %>%
  summarise(
    Threads = n_distinct(NG_TH_ID),  # Total threads
    Total_Comments = n(),  # Total comments
    Influential_Authors_Comments = sum(Author %in% influential_author_comments$Author),  # Influential authors' comments
    Total_Authors = n_distinct(Author),  # Total unique authors
    Influential_Authors = n_distinct(Author[Author %in% influential_author_comments$Author]),  # Unique influential authors
    Average_Comments_Per_Thread = n() / n_distinct(NG_TH_ID),  # Avg comments per thread
    Avg_Total_Comments_Sentiment_Score = mean(SentimentScore, na.rm = TRUE),  # Avg sentiment for all comments
    Avg_Influential_Comments_Sentiment_Score = mean(SentimentScore[Author %in% influential_author_comments$Author], na.rm = TRUE)  # Avg sentiment for influential comments
  )

# Add a totals row
totals_row <- descriptive_stats %>%
  summarise(
    newsgroup = "Total",
    Threads = sum(Threads),
    Total_Comments = sum(Total_Comments),
    Influential_Authors_Comments = sum(Influential_Authors_Comments),
    Total_Authors = n_distinct(all_comments_in_influential_threads$Author),
    Influential_Authors = n_distinct(influential_author_comments$Author),
    Average_Comments_Per_Thread = sum(Total_Comments) / sum(Threads),
    Avg_Total_Comments_Sentiment_Score = mean(all_comments_in_influential_threads$SentimentScore, na.rm = TRUE),
    Avg_Influential_Comments_Sentiment_Score = mean(influential_author_comments$SentimentScore, na.rm = TRUE)
  )

# Combine newsgroup stats with totals row
descriptive_stats <- bind_rows(descriptive_stats, totals_row)

# Save and display the table
tab_df(descriptive_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset3_statistics.html"))
```

## Dataset 3 Author Statistics
```{r Dataset 3 Author Statistics}
# Filter influential authors' participation in Dataset 3
dataset3_influential_comments <- relevant_comments %>%
  filter(Author %in% influential_authors$Author)

dataset3_influential_threads <- relevant_threads %>%
  filter(NG_TH_ID %in% dataset3_influential_comments$NG_TH_ID)

# Add descriptive statistics for each influential author
author_stats <- dataset3_influential_comments %>%
  group_by(Author) %>%
  summarise(
    Influence = unique(influential_authors$InfluenceScore[influential_authors$Author == Author]),
    Num_Comments = n_distinct(TH_CM_ID),  # Number of comments authored
    Num_Threads = n_distinct(NG_TH_ID),  # Number of threads participated in
    Threads_Started = sum(CM_ID == "CM00001", na.rm = TRUE),  # Threads started
    Avg_Sentiment = mean(SentimentScore, na.rm = TRUE),  # Average sentiment score
  )

# Filter out authors with missing Influence scores and sort by Influence
author_stats <- author_stats %>%
  filter(!is.na(Influence)) %>%
  arrange(desc(Influence))

# Save the table as an HTML file
tab_df(author_stats, file = file.path(output_directory, "Images and Tables/Tables/dataset3_author_statistics.html"))

# Display the table
print(author_stats)
```
